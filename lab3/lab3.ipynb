{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "SAMPLES_PER_EPOCH = 50000\n",
    "EPOCH_NUM = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def conv_layer(input, shape):\n",
    "    W = weight_variable(shape)\n",
    "    b = bias_variable([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input, W) + b)\n",
    "\n",
    "\n",
    "def full_layer(input, size):\n",
    "    in_size = int(input.get_shape()[1])\n",
    "    W = weight_variable([in_size, size])\n",
    "    b = bias_variable([size])\n",
    "    return tf.matmul(input, W) + b\n",
    "  \n",
    "def get_batch(features,labels,batch_size): \n",
    "    num_images = features.shape[0]\n",
    "    idx = np.random.choice(num_images,\n",
    "                           size=batch_size,\n",
    "                           replace=False)\n",
    "    features_batch = features[idx, :, :, :]\n",
    "    labels_batch = labels[idx, :]\n",
    "    return features_batch, labels_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 10)\n"
     ]
    }
   ],
   "source": [
    "(train_features, train_labels), (test_features, test_labels) = cifar10.load_data()\n",
    "\n",
    "num_train, img_rows, img_cols, img_channels =  train_features.shape\n",
    "num_test =  test_features.shape[0]\n",
    "num_classes = np.unique(train_labels).shape[0]\n",
    "\n",
    "train_features = train_features.astype('float32')/np.max(train_features)\n",
    "test_features = test_features.astype('float32')/np.max(test_features)\n",
    "\n",
    "\n",
    "train_labels = np_utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = np_utils.to_categorical(test_labels, num_classes)\n",
    "\n",
    "print(train_features.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32 , shape=[None , img_rows,img_cols,img_channels]) \n",
    "y_ = tf.placeholder(tf.float32 , shape=[None, 10]) \n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "test_features, test_labels = get_batch(test_features,test_labels,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('conv_1'): \n",
    "    conv1 = conv_layer(x , shape=[3, 3, img_channels, 64])\n",
    "    conv1_pool = max_pool_2x2( conv1 )\n",
    "\n",
    "with tf.name_scope('conv_2'): \n",
    "    conv2 = conv_layer(conv1_pool , shape=[3, 3, 64, 128])\n",
    "    conv2_pool = max_pool_2x2 ( conv2 )\n",
    "\n",
    "with tf.name_scope('conv_3'): \n",
    "    conv3 = conv_layer(conv2_pool , shape=[3, 3, 128, 256] )\n",
    "    conv3_pool = max_pool_2x2 ( conv3 )\n",
    "    conv3_flat = tf.contrib.layers.flatten(conv3_pool) \n",
    "\n",
    "with tf.name_scope('full_1'): \n",
    "    full_1 = tf.nn.relu(full_layer(conv3_flat , 512))\n",
    "\n",
    "with tf.name_scope('dropout'): \n",
    "    full1_drop = tf.nn.dropout(full_1 , keep_prob=keep_prob) \n",
    "\n",
    "with tf.name_scope('activations'): \n",
    "    y_conv = full_layer(full1_drop , 10) \n",
    "    tf.summary.scalar('cross_entropy_loss',y_conv)\t\n",
    "\n",
    "with tf.name_scope('cross'): \n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y_conv , labels=y_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 32, 32, 3) (500, 10)\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv , 1), tf.argmax(y_, 1)) \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction , tf.float32))\n",
    "print(test_features.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 11.170629978179932, epoch 0, training accuracy 0.5\n",
      "time 22.2426176071167, epoch 1, training accuracy 0.53125\n",
      "time 33.315584659576416, epoch 2, training accuracy 0.71875\n",
      "time 44.401983976364136, epoch 3, training accuracy 0.625\n",
      "time 55.49939465522766, epoch 4, training accuracy 0.625\n",
      "time 66.6056764125824, epoch 5, training accuracy 0.65625\n",
      "time 77.69407176971436, epoch 6, training accuracy 0.53125\n",
      "time 88.78852772712708, epoch 7, training accuracy 0.8125\n",
      "time 99.8799364566803, epoch 8, training accuracy 0.75\n",
      "time 110.9821457862854, epoch 9, training accuracy 0.78125\n",
      "time 122.07155275344849, epoch 10, training accuracy 0.75\n",
      "time 133.16862177848816, epoch 11, training accuracy 0.53125\n",
      "time 144.2646517753601, epoch 12, training accuracy 0.84375\n",
      "time 155.369304895401, epoch 13, training accuracy 0.6875\n",
      "time 166.47116947174072, epoch 14, training accuracy 0.6875\n",
      "time 177.60183787345886, epoch 15, training accuracy 0.78125\n",
      "time 188.7622423171997, epoch 16, training accuracy 0.8125\n",
      "time 200.05301141738892, epoch 17, training accuracy 0.6875\n",
      "time 211.20253896713257, epoch 18, training accuracy 0.78125\n",
      "time 222.29078698158264, epoch 19, training accuracy 0.625\n",
      "time 233.44127559661865, epoch 20, training accuracy 0.78125\n",
      "time 244.75271940231323, epoch 21, training accuracy 0.8125\n",
      "time 255.90037059783936, epoch 22, training accuracy 0.65625\n",
      "time 267.04259300231934, epoch 23, training accuracy 0.6875\n",
      "time 278.1788878440857, epoch 24, training accuracy 0.8125\n",
      "time 289.5003581047058, epoch 25, training accuracy 0.78125\n",
      "time 300.6919059753418, epoch 26, training accuracy 0.71875\n",
      "time 311.91286635398865, epoch 27, training accuracy 0.875\n",
      "time 323.28631043434143, epoch 28, training accuracy 0.75\n",
      "time 334.5447287559509, epoch 29, training accuracy 0.8125\n",
      "time 345.7784652709961, epoch 30, training accuracy 0.6875\n",
      "time 357.12252616882324, epoch 31, training accuracy 0.78125\n",
      "time 368.3254096508026, epoch 32, training accuracy 0.8125\n",
      "time 379.4370505809784, epoch 33, training accuracy 0.75\n",
      "time 390.54856848716736, epoch 34, training accuracy 0.65625\n",
      "time 401.75733256340027, epoch 35, training accuracy 0.59375\n",
      "time 412.9242844581604, epoch 36, training accuracy 0.8125\n",
      "time 424.04533672332764, epoch 37, training accuracy 0.75\n",
      "time 435.21942806243896, epoch 38, training accuracy 0.8125\n",
      "time 446.37181854248047, epoch 39, training accuracy 0.78125\n",
      "time 457.5071220397949, epoch 40, training accuracy 0.75\n",
      "time 468.63959407806396, epoch 41, training accuracy 0.65625\n",
      "time 479.75940203666687, epoch 42, training accuracy 0.75\n",
      "time 490.95231580734253, epoch 43, training accuracy 0.75\n",
      "time 502.0986351966858, epoch 44, training accuracy 0.84375\n",
      "time 513.2590925693512, epoch 45, training accuracy 0.84375\n",
      "time 524.4387941360474, epoch 46, training accuracy 0.65625\n",
      "time 535.8544759750366, epoch 47, training accuracy 0.6875\n",
      "time 547.678676366806, epoch 48, training accuracy 0.75\n",
      "time 559.0756106376648, epoch 49, training accuracy 0.84375\n",
      "test accuracy: 0.7680000066757202\n"
     ]
    }
   ],
   "source": [
    " with tf.device(\"/gpu:0\"):   \n",
    "    with tf.Session() as sess: \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for j in range(EPOCH_NUM):\n",
    "            for i in range(SAMPLES_PER_EPOCH // BATCH_SIZE):\n",
    "                batch_trainf, batch_trainl = get_batch(train_features,train_labels,BATCH_SIZE)\n",
    "                sess.run(train_step , feed_dict={x: batch_trainf, y_: batch_trainl, keep_prob: 0.5}) \n",
    "            batch_trainf, batch_trainl = get_batch(test_features,test_labels,32)\n",
    "            train_accuracy = sess.run(accuracy , feed_dict={x: batch_trainf, y_: batch_trainl, keep_prob: 1.0}) \n",
    "            print(\"time {}, epoch {}, training accuracy {}\".format(time.time() - start_time, j, train_accuracy)) \n",
    "\n",
    "        test_accuracy = np.mean([sess.run(accuracy , feed_dict={x:test_features, y_:test_labels, keep_prob:1.0})])\n",
    "        print(\"test accuracy: {}\".format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
